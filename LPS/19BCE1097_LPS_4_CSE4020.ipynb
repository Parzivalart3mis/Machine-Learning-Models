{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "19BCE1097 - LPS 4 - CSE4020.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "S0e-llRRXNfc",
        "Y_QxMtk9XcfU",
        "rj3jXs7wX6mK",
        "eI7MAWMCemSi",
        "-mJeH4Vjhqvn",
        "sAXSb82Oh-Uz",
        "aagu1j9SjZF0",
        "IeqDFc2qU7vD",
        "eJJFv5WtZ-mL",
        "_QtRJoTWOSez"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfHkFayISrTa"
      },
      "source": [
        "## **Name: Yash Vardhan Sharma**\n",
        "## **Registration Number: 19BCE1097**\n",
        "\n",
        "Code of Academic Integrity\n",
        "\n",
        "* I affirm that\n",
        "* This work is my own original work and is not a borrowed work,\n",
        "\n",
        "*   This work is my own original work and is not a borrowed work, either from other students or from assignments for other courses.\n",
        "\n",
        "*   I have not given or received any unauthorized help on this as\u0002signment.\n",
        "\n",
        "*   This submission is free from Plagiarism, Fabrication of facts, Unauthorized assistance, collusion\n",
        "\n",
        "*   This submission gives proper credit to sources and references, acknowledges the contributions and ideas of others relevant to this academic work.\n",
        "\n",
        "*   This submission was prepared by me fully adhering to the rules that govern this assignment regarding resource material, elec\u0002tronic aids, copying, collaborating with others, or engaging in any other behavior that subverts the purpose of the assignment and the directions of the teacher.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoYPBEQWlJd"
      },
      "source": [
        "# **Lab Practice Sheet 4**\n",
        "\n",
        "\n",
        "## Simple Linear Regression, Multiple Linear Regression(Gradient descent method)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOzBhn7oX6oB"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2neqTLi4SXIx"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error as mae\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.datasets import make_regression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3gV_9JYFWgg7"
      },
      "source": [
        "### 4. Generate a dataset D with ‘make regression’ which has 1000 data-points and two input features. partition the dataset in to training data and test data in the ratio of 80:20. Use D to train multiple linear regression model(Batch Gradient Descent) with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if-V7qSSBhjh"
      },
      "source": [
        "class batch_regressor:\n",
        "\n",
        "  def __init__(self,X):    \n",
        "    self.W = np.random.randn(X.shape[1],1)    \n",
        "    \n",
        "\n",
        "  def fit(self,X, y, learning_rate=0.1, numEpochs=2000):\n",
        "    num_of_samples = len(X)    \n",
        "    for epoch in range(numEpochs):      \n",
        "      X, y = shuffle(X, y)\n",
        "      delta = (X.T.dot(X.dot(self.W)-y.reshape(-1,1))/num_of_samples)        \n",
        "      self.W = self.W - learning_rate * delta\n",
        "      learning_rate = learning_rate/1.02\n",
        "    \n",
        "    return self.W\n",
        "    \n",
        "  def predict(self,X,W):\n",
        "    return X.dot(W)\n",
        "\n",
        "  def measure(self,y_predict,y_actual):\n",
        "    return np.sqrt(mean_squared_error(y_predict, y_actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfYGJWg6BfXf"
      },
      "source": [
        "def func_MLR5(D, Arr, size):\n",
        "  X_traind, X_testd, y_traind, y_testd = train_test_split(Arr ,D['Y'], test_size=size, random_state=4)\n",
        "  \n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  X_train = scaler.fit_transform(X_traind)\n",
        "  X_test = scaler.transform(X_testd)\n",
        "  \n",
        "  X_train_b = np.asarray(X_train)\n",
        "  Y_train = np.asarray(y_traind)\n",
        "  X_test_b = np.asarray(X_test)\n",
        "  bgd = batch_regressor(X_train_b)\n",
        "  \n",
        "  w = bgd.fit(X_train_b,Y_train)\n",
        "  predicted_train =bgd.predict(X_train_b,w)\n",
        "  rmse_train = bgd.measure(predicted_train,Y_train)\n",
        "  predicted_test =bgd.predict(X_test_b,w)\n",
        "  rmse_test = bgd.measure(predicted_test,y_testd)\n",
        "  print('For test data size', size*100)\n",
        "  print('SDE train Error', rmse_train)\n",
        "  print('SDE test Error', rmse_test)\n",
        "  per = (rmse_train+rmse_test)/2\n",
        "  print('Performane', per)\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JGeFZh3W6w7"
      },
      "source": [
        "#### a) A polynomial of degree 1 (with all the terms)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "PrbgmbL8WrkL",
        "outputId": "a67e9c64-ff04-48b7-9a6a-9f588dfea6c1"
      },
      "source": [
        "variables, target = make_regression(n_samples=1000, n_features=1)\n",
        "df = pd.DataFrame(variables)\n",
        "df['target'] = target\n",
        "df = df.set_axis(['X','Y'], axis=1, inplace=False)\n",
        "Ones = np.ones(1000)\n",
        "df.insert(0,'Bias',Ones)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bias</th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.574643</td>\n",
              "      <td>16.553724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.480794</td>\n",
              "      <td>42.657170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.963618</td>\n",
              "      <td>27.758919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.679723</td>\n",
              "      <td>19.580764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.709927</td>\n",
              "      <td>-20.450842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.725827</td>\n",
              "      <td>20.908861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.052963</td>\n",
              "      <td>1.525692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.106209</td>\n",
              "      <td>31.866507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.168290</td>\n",
              "      <td>33.654897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.968916</td>\n",
              "      <td>56.718475</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Bias         X          Y\n",
              "0     1.0  0.574643  16.553724\n",
              "1     1.0  1.480794  42.657170\n",
              "2     1.0  0.963618  27.758919\n",
              "3     1.0  0.679723  19.580764\n",
              "4     1.0 -0.709927 -20.450842\n",
              "..    ...       ...        ...\n",
              "995   1.0  0.725827  20.908861\n",
              "996   1.0  0.052963   1.525692\n",
              "997   1.0  1.106209  31.866507\n",
              "998   1.0  1.168290  33.654897\n",
              "999   1.0  1.968916  56.718475\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTdZkQcKWz4T",
        "outputId": "35666bf9-2d02-4ec8-ae9a-eda8c31324d8"
      },
      "source": [
        "func_MLR5(df, np.asarray(df[['Bias','X']]), .20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For test data size 20.0\n",
            "SDE train Error 27.080556101964774\n",
            "SDE test Error 26.617540383531004\n",
            "Performane 26.84904824274789\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0e-llRRXNfc"
      },
      "source": [
        "#### b) A polynomial of degree 2 (with all the terms)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "KE3B0sjEW1D_",
        "outputId": "55ed6c06-caf2-439c-ee8e-ff5298ea122f"
      },
      "source": [
        "variables2, target2 = make_regression(n_samples=1000, n_features=2)\n",
        "df2 = pd.DataFrame(variables2)\n",
        "df2['target2'] = target2\n",
        "df2 = df2.set_axis(['X','X^2','Y'], axis=1, inplace=False)\n",
        "Ones = np.ones(1000)\n",
        "df2.insert(0,'Bias',Ones)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bias</th>\n",
              "      <th>X</th>\n",
              "      <th>X^2</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.372644</td>\n",
              "      <td>0.557586</td>\n",
              "      <td>51.610508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.783108</td>\n",
              "      <td>0.429697</td>\n",
              "      <td>-53.103855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>2.640964</td>\n",
              "      <td>-0.432681</td>\n",
              "      <td>214.221845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.286907</td>\n",
              "      <td>-0.370757</td>\n",
              "      <td>-124.490623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.059204</td>\n",
              "      <td>-1.867448</td>\n",
              "      <td>27.366335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.810681</td>\n",
              "      <td>0.348563</td>\n",
              "      <td>-58.301089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.992582</td>\n",
              "      <td>0.355535</td>\n",
              "      <td>185.201620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.082652</td>\n",
              "      <td>0.908038</td>\n",
              "      <td>38.559165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.227548</td>\n",
              "      <td>0.344563</td>\n",
              "      <td>31.656124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.932139</td>\n",
              "      <td>0.640628</td>\n",
              "      <td>-145.523626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Bias         X       X^2           Y\n",
              "0     1.0  0.372644  0.557586   51.610508\n",
              "1     1.0 -0.783108  0.429697  -53.103855\n",
              "2     1.0  2.640964 -0.432681  214.221845\n",
              "3     1.0 -1.286907 -0.370757 -124.490623\n",
              "4     1.0  1.059204 -1.867448   27.366335\n",
              "..    ...       ...       ...         ...\n",
              "995   1.0 -0.810681  0.348563  -58.301089\n",
              "996   1.0  1.992582  0.355535  185.201620\n",
              "997   1.0  0.082652  0.908038   38.559165\n",
              "998   1.0  0.227548  0.344563   31.656124\n",
              "999   1.0 -1.932139  0.640628 -145.523626\n",
              "\n",
              "[1000 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIMRUHUzXX97",
        "outputId": "18b92acb-ae90-4e47-bb18-f934289730c7"
      },
      "source": [
        "func_MLR5(df2, np.asarray(df2[['Bias','X','X^2']]), .20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For test data size 20.0\n",
            "SDE train Error 92.4968399276448\n",
            "SDE test Error 88.2704747133279\n",
            "Performane 90.38365732048635\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_QxMtk9XcfU"
      },
      "source": [
        "#### c) A polynomial of degree 3 (with all the terms)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "mBf5nDTLXg5Q",
        "outputId": "e3b3bf1c-df9c-46a6-861b-e61617714721"
      },
      "source": [
        "variables3, target3 = make_regression(n_samples=1000, n_features=3)\n",
        "df3 = pd.DataFrame(variables3)\n",
        "df3['target3'] = target3\n",
        "df3 = df3.set_axis(['X','X^2','X^3','Y'], axis=1, inplace=False)\n",
        "Ones = np.ones(1000)\n",
        "df3.insert(0,'Bias',Ones)\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bias</th>\n",
              "      <th>X</th>\n",
              "      <th>X^2</th>\n",
              "      <th>X^3</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.344116</td>\n",
              "      <td>-0.380981</td>\n",
              "      <td>-0.928843</td>\n",
              "      <td>-29.643511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.586351</td>\n",
              "      <td>1.035871</td>\n",
              "      <td>-0.454752</td>\n",
              "      <td>-21.996124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.778447</td>\n",
              "      <td>-1.535797</td>\n",
              "      <td>1.274346</td>\n",
              "      <td>-135.063065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.558475</td>\n",
              "      <td>-0.942666</td>\n",
              "      <td>-0.997694</td>\n",
              "      <td>-4.145483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.363036</td>\n",
              "      <td>1.153065</td>\n",
              "      <td>-0.929223</td>\n",
              "      <td>47.291719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.198725</td>\n",
              "      <td>1.164364</td>\n",
              "      <td>-0.459037</td>\n",
              "      <td>90.856627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.733288</td>\n",
              "      <td>-0.392959</td>\n",
              "      <td>1.175504</td>\n",
              "      <td>95.566333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.000989</td>\n",
              "      <td>1.408787</td>\n",
              "      <td>-1.787660</td>\n",
              "      <td>69.103410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.939564</td>\n",
              "      <td>-0.174418</td>\n",
              "      <td>2.120622</td>\n",
              "      <td>-21.381867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.628914</td>\n",
              "      <td>-0.650538</td>\n",
              "      <td>-0.055264</td>\n",
              "      <td>-87.469019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Bias         X       X^2       X^3           Y\n",
              "0     1.0  0.344116 -0.380981 -0.928843  -29.643511\n",
              "1     1.0 -1.586351  1.035871 -0.454752  -21.996124\n",
              "2     1.0 -0.778447 -1.535797  1.274346 -135.063065\n",
              "3     1.0  1.558475 -0.942666 -0.997694   -4.145483\n",
              "4     1.0 -0.363036  1.153065 -0.929223   47.291719\n",
              "..    ...       ...       ...       ...         ...\n",
              "995   1.0  0.198725  1.164364 -0.459037   90.856627\n",
              "996   1.0  1.733288 -0.392959  1.175504   95.566333\n",
              "997   1.0 -0.000989  1.408787 -1.787660   69.103410\n",
              "998   1.0 -0.939564 -0.174418  2.120622  -21.381867\n",
              "999   1.0 -0.628914 -0.650538 -0.055264  -87.469019\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xig8lb0JX0-v",
        "outputId": "966a8613-8698-4704-86e2-5d68ecb44074"
      },
      "source": [
        "func_MLR5(df3, np.asarray(df3[['Bias','X','X^2','X^3']]), .20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For test data size 20.0\n",
            "SDE train Error 93.1673634496944\n",
            "SDE test Error 102.9768405981134\n",
            "Performane 98.07210202390391\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Gd-iuOSDbjW"
      },
      "source": [
        "We can clearly observe that the polynomial of degree 2 has the highest value of performance of 109 and the lowest performance is the polynomial of degree 1 which is 30. Hence, the polynomial of degree 1 learns the best."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rj3jXs7wX6mK"
      },
      "source": [
        "### 5. Generate a dataset D with ‘make regression’ (choose the noise parameter as zero) which has 1000 data points with two input features. Create a sequence of datasets D1,D2,D3,D4,D5 from D by injecting 20%, 40%, 60%,80% 0%,100% of noise respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj6pTjVH-3GS"
      },
      "source": [
        "class sgd_regressor:\n",
        "\n",
        "  def __init__(self,X):    \n",
        "    self.W = np.random.randn(X.shape[1],1)    \n",
        "    \n",
        "\n",
        "  def fit(self,X, y, learning_rate=0.1, numEpochs=2000):\n",
        "    num_of_samples = len(X)\n",
        "    xbShuffled, yShuffled = shuffle(X, y)\n",
        "    for epoch in range(numEpochs):\n",
        "      \n",
        "      for i in range(num_of_samples):        \n",
        "        X = xbShuffled[i:i+1]\n",
        "        yi = yShuffled[i:i+1]\n",
        "        \n",
        "        delta = X.T.dot(X.dot(self.W)-yi.reshape(-1,1))\n",
        "                \n",
        "        self.W = self.W - learning_rate * delta\n",
        "      learning_rate = learning_rate/1.02\n",
        "    return self.W\n",
        "    \n",
        "  def predict(self,X,W):\n",
        "    return X.dot(W)\n",
        "\n",
        "  def measure(self,y_predict,y_actual):\n",
        "    return np.sqrt(mean_squared_error(y_predict, y_actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "qVTo3NgUX-ZP",
        "outputId": "75405f90-b1c0-4b64-ee7a-5ed21fe164e7"
      },
      "source": [
        "data=make_regression(n_samples=1000, n_features=4, n_informative=2,n_targets=1,bias=0.0, effective_rank=None, noise=0.0, tail_strength=0.5, coef=False, shuffle=True, random_state=4)\n",
        "D = pd.DataFrame(data[0],columns=['x'+str(i) for i in range(1,5)])\n",
        "D['y'] = data[1]\n",
        "D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.467241</td>\n",
              "      <td>-1.473583</td>\n",
              "      <td>-0.400955</td>\n",
              "      <td>0.122534</td>\n",
              "      <td>-8.233396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.562864</td>\n",
              "      <td>0.824745</td>\n",
              "      <td>0.067969</td>\n",
              "      <td>-0.451925</td>\n",
              "      <td>-32.668176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.135040</td>\n",
              "      <td>-0.703702</td>\n",
              "      <td>1.021038</td>\n",
              "      <td>-1.863831</td>\n",
              "      <td>-101.635163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.044241</td>\n",
              "      <td>-1.572799</td>\n",
              "      <td>-0.254212</td>\n",
              "      <td>0.070336</td>\n",
              "      <td>-5.800989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.282083</td>\n",
              "      <td>-0.252198</td>\n",
              "      <td>2.115736</td>\n",
              "      <td>-0.241259</td>\n",
              "      <td>75.468655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-0.095225</td>\n",
              "      <td>1.387069</td>\n",
              "      <td>1.649444</td>\n",
              "      <td>-0.031263</td>\n",
              "      <td>71.226014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-0.998075</td>\n",
              "      <td>-0.395259</td>\n",
              "      <td>1.968719</td>\n",
              "      <td>1.672906</td>\n",
              "      <td>220.131219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.471661</td>\n",
              "      <td>1.200509</td>\n",
              "      <td>0.300600</td>\n",
              "      <td>0.695093</td>\n",
              "      <td>68.347315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-1.360243</td>\n",
              "      <td>-0.350150</td>\n",
              "      <td>-1.032448</td>\n",
              "      <td>-0.329359</td>\n",
              "      <td>-72.150524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-1.933564</td>\n",
              "      <td>0.706748</td>\n",
              "      <td>-2.552561</td>\n",
              "      <td>-0.454133</td>\n",
              "      <td>-149.926053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           x1        x2        x3        x4           y\n",
              "0    0.467241 -1.473583 -0.400955  0.122534   -8.233396\n",
              "1   -0.562864  0.824745  0.067969 -0.451925  -32.668176\n",
              "2   -1.135040 -0.703702  1.021038 -1.863831 -101.635163\n",
              "3   -1.044241 -1.572799 -0.254212  0.070336   -5.800989\n",
              "4   -1.282083 -0.252198  2.115736 -0.241259   75.468655\n",
              "..        ...       ...       ...       ...         ...\n",
              "995 -0.095225  1.387069  1.649444 -0.031263   71.226014\n",
              "996 -0.998075 -0.395259  1.968719  1.672906  220.131219\n",
              "997  0.471661  1.200509  0.300600  0.695093   68.347315\n",
              "998 -1.360243 -0.350150 -1.032448 -0.329359  -72.150524\n",
              "999 -1.933564  0.706748 -2.552561 -0.454133 -149.926053\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fZodf8ucWy5"
      },
      "source": [
        "def noiseinduce(mu, sigma, D):\n",
        "     noise = np.random.normal(mu, sigma,[1000,5])\n",
        "     ret_df = D+noise\n",
        "     return(ret_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "810V0BzpdG0F",
        "outputId": "a80ffdf5-4b1e-4f8c-dcfc-b03c44ebb799"
      },
      "source": [
        "D1 = noiseinduce(0, 0.2, D)\n",
        "D1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.567150</td>\n",
              "      <td>-1.667370</td>\n",
              "      <td>-0.492884</td>\n",
              "      <td>0.371571</td>\n",
              "      <td>-8.392709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.672347</td>\n",
              "      <td>0.955843</td>\n",
              "      <td>-0.116298</td>\n",
              "      <td>-0.540246</td>\n",
              "      <td>-32.899182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.842093</td>\n",
              "      <td>-0.704843</td>\n",
              "      <td>0.732768</td>\n",
              "      <td>-1.838283</td>\n",
              "      <td>-101.898239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1.193139</td>\n",
              "      <td>-1.436363</td>\n",
              "      <td>-0.535512</td>\n",
              "      <td>-0.205308</td>\n",
              "      <td>-6.051714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.094264</td>\n",
              "      <td>-0.346609</td>\n",
              "      <td>1.866412</td>\n",
              "      <td>-0.266240</td>\n",
              "      <td>75.320322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-0.053538</td>\n",
              "      <td>1.273957</td>\n",
              "      <td>1.629617</td>\n",
              "      <td>0.032977</td>\n",
              "      <td>70.860732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-1.156957</td>\n",
              "      <td>-0.750717</td>\n",
              "      <td>2.343071</td>\n",
              "      <td>1.574448</td>\n",
              "      <td>220.271937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.436772</td>\n",
              "      <td>1.344845</td>\n",
              "      <td>0.301349</td>\n",
              "      <td>0.975483</td>\n",
              "      <td>67.901933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-1.329372</td>\n",
              "      <td>-0.150073</td>\n",
              "      <td>-0.955337</td>\n",
              "      <td>-0.394892</td>\n",
              "      <td>-72.507827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>-1.717710</td>\n",
              "      <td>0.793126</td>\n",
              "      <td>-2.749476</td>\n",
              "      <td>-0.977439</td>\n",
              "      <td>-150.193715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           x1        x2        x3        x4           y\n",
              "0    0.567150 -1.667370 -0.492884  0.371571   -8.392709\n",
              "1   -0.672347  0.955843 -0.116298 -0.540246  -32.899182\n",
              "2   -0.842093 -0.704843  0.732768 -1.838283 -101.898239\n",
              "3   -1.193139 -1.436363 -0.535512 -0.205308   -6.051714\n",
              "4   -1.094264 -0.346609  1.866412 -0.266240   75.320322\n",
              "..        ...       ...       ...       ...         ...\n",
              "995 -0.053538  1.273957  1.629617  0.032977   70.860732\n",
              "996 -1.156957 -0.750717  2.343071  1.574448  220.271937\n",
              "997  0.436772  1.344845  0.301349  0.975483   67.901933\n",
              "998 -1.329372 -0.150073 -0.955337 -0.394892  -72.507827\n",
              "999 -1.717710  0.793126 -2.749476 -0.977439 -150.193715\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3VCq64MdZer"
      },
      "source": [
        "#Similarly\n",
        "D2 = noiseinduce(0, 0.4, D)\n",
        "D3 = noiseinduce(0, 0.6, D)\n",
        "D4 = noiseinduce(0, 0.8, D)\n",
        "D5 = noiseinduce(0, 1.0, D)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI7MAWMCemSi"
      },
      "source": [
        "##### a) Using D,D1,D2,D3,D4,D5,D6 Train the ‘multiple linear regression model(Stochastic Gradient Descent)’ separately with a polynomial of degree 1. In each experiment , have the training data and the test in the ratio of 75:25."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXHJBQ13eNbS"
      },
      "source": [
        "def func_MLR(D):\n",
        "  X_traind, X_testd, y_traind, y_testd = train_test_split(np.asarray(D[['x1','x2','x3','x4']]),D['y'], test_size=0.25, random_state=4)\n",
        "  \n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  X_train = scaler.fit_transform(X_traind)\n",
        "  X_test = scaler.transform(X_testd)\n",
        "  \n",
        "  X_train_b = np.asarray(X_train)\n",
        "  Y_train = np.asarray(y_traind)\n",
        "  X_test_b = np.asarray(X_test)\n",
        "  sgd = sgd_regressor(X_train_b)\n",
        "  \n",
        "  w = sgd.fit(X_train_b,Y_train)\n",
        "  predicted_train =sgd.predict(X_train_b,w)\n",
        "  rmse_train = sgd.measure(predicted_train,Y_train)\n",
        "  predicted_test =sgd.predict(X_test_b,w)\n",
        "  rmse_test = sgd.measure(predicted_test,y_testd)\n",
        "  return(rmse_train, rmse_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z5aOSTNg4sy",
        "outputId": "20846106-b010-4714-8c7f-4bfa821a85ac"
      },
      "source": [
        "kd1, ld1 = func_MLR(D1)\n",
        "print('Training Mean Absolute Error', kd1)\n",
        "print('Test Mean Absolute Error', ld1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Absolute Error 61.68758396253619\n",
            "Test Mean Absolute Error 60.212554165981075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnygQCknhR13",
        "outputId": "91ec4ed1-936f-418f-800c-8360c7099e13"
      },
      "source": [
        "kd2, ld2 = func_MLR(D2)\n",
        "print('Training Mean Absolute Error', kd2)\n",
        "print('Test Mean Absolute Error', ld2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Absolute Error 65.81119154592223\n",
            "Test Mean Absolute Error 63.22884799797048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6H_MHOhhSdX",
        "outputId": "da00e1ed-627a-4637-c5ea-998301c13f61"
      },
      "source": [
        "kd3, ld3 = func_MLR(D3)\n",
        "print('Training Mean Absolute Error', kd3)\n",
        "print('Test Mean Absolute Error', ld3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Absolute Error 68.46788347318201\n",
            "Test Mean Absolute Error 64.4916154543424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VaX0qovhTIs",
        "outputId": "583cc8fe-392e-4187-c4a9-35356572fb71"
      },
      "source": [
        "kd4, ld4 = func_MLR(D4)\n",
        "print('Training Mean Absolute Error', kd4)\n",
        "print('Test Mean Absolute Error', ld4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Absolute Error 69.64652257288735\n",
            "Test Mean Absolute Error 70.04117681549103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fde1hJZBhTzj",
        "outputId": "46299731-b895-4d7e-9357-f3e436a2af9b"
      },
      "source": [
        "kd5, ld5 = func_MLR(D5)\n",
        "print('Training Mean Absolute Error', kd5)\n",
        "print('Test Mean Absolute Error', ld5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Mean Absolute Error 76.72457579825273\n",
            "Test Mean Absolute Error 73.90408790600372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mJeH4Vjhqvn"
      },
      "source": [
        "#### b) Compute the performance of the model as the average of the training data error and the test data error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laxdo_zVhvM4",
        "outputId": "09dcaf86-c10a-4b5d-896f-b7d4dcbe1774"
      },
      "source": [
        "p1=(kd1+ld1)/2\n",
        "print('Performance in D1', p1)\n",
        "p2 = (kd2+ld2)/2\n",
        "print('Performance in D2', p2)\n",
        "p3 = (kd3+ld3)/2\n",
        "print('Performance in D3', p3)\n",
        "p4 = (kd4+ld4)/2\n",
        "print('Performance in D4', p4)\n",
        "p5 = (kd5+ld5)/2\n",
        "print('Performance in D5', p5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance in D1 60.95006906425863\n",
            "Performance in D2 64.52001977194635\n",
            "Performance in D3 66.4797494637622\n",
            "Performance in D4 69.84384969418919\n",
            "Performance in D5 75.31433185212822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAXSb82Oh-Uz"
      },
      "source": [
        "#### c) Plot the graph: noise vs error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "70yYV717iBoZ",
        "outputId": "dda0725e-3f7f-40a4-c8ad-a431dd3c6892"
      },
      "source": [
        "data = {'Noise': [.2, .4, .6, .8, 1], 'Error':[p1, p2, p3, p4, p5]}\n",
        "df_graph = pd.DataFrame(data)\n",
        "df_graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Noise</th>\n",
              "      <th>Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.2</td>\n",
              "      <td>60.950069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.4</td>\n",
              "      <td>64.520020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.6</td>\n",
              "      <td>66.479749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.8</td>\n",
              "      <td>69.843850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>75.314332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Noise      Error\n",
              "0    0.2  60.950069\n",
              "1    0.4  64.520020\n",
              "2    0.6  66.479749\n",
              "3    0.8  69.843850\n",
              "4    1.0  75.314332"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "bh683yp6iw6i",
        "outputId": "03ef328e-b6f0-4c6a-87ac-50a9f0a0efc2"
      },
      "source": [
        "df_graph.plot('Noise', 'Error', marker = 's' ,color = 'red')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0b7cb84990>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aagu1j9SjZF0"
      },
      "source": [
        "#### d) Based on the results of the experiment, comment on the statement: ‘ more noise in the data set, less accuracy’"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16MhwOHBjkVk"
      },
      "source": [
        "It is clear that the graph ploted above that as the noise increases the value of error also increases hence, the more the noise in the data the less is the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeqDFc2qU7vD"
      },
      "source": [
        "### 8. Consider a dataset D which has two input features with 500 data points. You can either download a dataset or generate a synthetic dataset. Implement a multiple linear regression model (Stochastic Gradient Descent) and learn the curve that best fits the dataset, subject to the following condition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "RNOZMcU8VBV4",
        "outputId": "91e6f455-7fcd-4eb4-c1a4-21943a0885df"
      },
      "source": [
        "variables, target = make_regression(n_samples=500, n_features=1)\n",
        "df = pd.DataFrame(variables)\n",
        "df['target'] = target\n",
        "df = df.set_axis(['x','Y'], axis = 1, inplace = False)\n",
        "df['x^2'] = df['x'].pow(2)\n",
        "Ones = np.ones(500)\n",
        "df.insert(0,'Bias',Ones)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bias</th>\n",
              "      <th>x</th>\n",
              "      <th>Y</th>\n",
              "      <th>x^2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.003470</td>\n",
              "      <td>-0.172244</td>\n",
              "      <td>0.000012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.719488</td>\n",
              "      <td>-85.360576</td>\n",
              "      <td>2.956640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.379030</td>\n",
              "      <td>-18.816174</td>\n",
              "      <td>0.143663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.123249</td>\n",
              "      <td>6.118437</td>\n",
              "      <td>0.015190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.246640</td>\n",
              "      <td>-12.243960</td>\n",
              "      <td>0.060831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.472556</td>\n",
              "      <td>-73.102139</td>\n",
              "      <td>2.168423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.446351</td>\n",
              "      <td>-22.158215</td>\n",
              "      <td>0.199229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.164049</td>\n",
              "      <td>-8.143906</td>\n",
              "      <td>0.026912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.255920</td>\n",
              "      <td>-12.704639</td>\n",
              "      <td>0.065495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.549559</td>\n",
              "      <td>27.281781</td>\n",
              "      <td>0.302015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Bias         x          Y       x^2\n",
              "0     1.0 -0.003470  -0.172244  0.000012\n",
              "1     1.0 -1.719488 -85.360576  2.956640\n",
              "2     1.0 -0.379030 -18.816174  0.143663\n",
              "3     1.0  0.123249   6.118437  0.015190\n",
              "4     1.0 -0.246640 -12.243960  0.060831\n",
              "..    ...       ...        ...       ...\n",
              "495   1.0 -1.472556 -73.102139  2.168423\n",
              "496   1.0 -0.446351 -22.158215  0.199229\n",
              "497   1.0 -0.164049  -8.143906  0.026912\n",
              "498   1.0 -0.255920 -12.704639  0.065495\n",
              "499   1.0  0.549559  27.281781  0.302015\n",
              "\n",
              "[500 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgECq17Kp0ro"
      },
      "source": [
        "class sgd_regressor:\n",
        "\n",
        "  def __init__(self,X):    \n",
        "    self.W = np.random.randn(X.shape[1],1)    \n",
        "    \n",
        "\n",
        "  def fit(self,X, y, learning_rate=0.1, numEpochs=2000):\n",
        "    num_of_samples = len(X)\n",
        "    xbShuffled, yShuffled = shuffle(X, y)\n",
        "    for epoch in range(numEpochs):\n",
        "      \n",
        "      for i in range(num_of_samples):        \n",
        "        X = xbShuffled[i:i+1]\n",
        "        yi = yShuffled[i:i+1]\n",
        "        \n",
        "        delta = X.T.dot(X.dot(self.W)-yi.reshape(-1,1))\n",
        "                \n",
        "        self.W = self.W - learning_rate * delta\n",
        "      learning_rate = learning_rate/1.02\n",
        "    return self.W\n",
        "    \n",
        "  def predict(self,X,W):\n",
        "    return X.dot(W)\n",
        "\n",
        "  def measure(self,y_predict,y_actual):\n",
        "    return np.sqrt(mean_squared_error(y_predict, y_actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYdZM0hgVqbZ"
      },
      "source": [
        "def func_MLR4(D, Arr, size):\n",
        "  X_traind, X_testd, y_traind, y_testd = train_test_split(Arr ,D['Y'], test_size=size, random_state=4)\n",
        "  \n",
        "  scaler = MinMaxScaler(feature_range=(0,1))\n",
        "  X_train = scaler.fit_transform(X_traind)\n",
        "  X_test = scaler.transform(X_testd)\n",
        "  \n",
        "  X_train_b = np.asarray(X_train)\n",
        "  Y_train = np.asarray(y_traind)\n",
        "  X_test_b = np.asarray(X_test)\n",
        "  sgd = sgd_regressor(X_train_b)\n",
        "  \n",
        "  w = sgd.fit(X_train_b,Y_train)\n",
        "  predicted_train =sgd.predict(X_train_b,w)\n",
        "  rmse_train = sgd.measure(predicted_train,Y_train)\n",
        "  predicted_test =sgd.predict(X_test_b,w)\n",
        "  rmse_test = sgd.measure(predicted_test,y_testd)\n",
        "  print('For testing data size', size*100)\n",
        "  print('SDE training Error', rmse_train)\n",
        "  print('SDE testing Error', rmse_test)\n",
        "  per = (rmse_train+rmse_test)/2\n",
        "  print('Performane', per)\n",
        "  print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBeCYXGPVtDH",
        "outputId": "9cd8c3a2-b7d8-44e0-e42c-4e6db9f6a6f5"
      },
      "source": [
        "x = 0.3\n",
        "while(x<= 0.7):\n",
        "  func_MLR4(df, np.asarray(df[['Bias','x','x^2']]), x)\n",
        "  x = round(x + 0.1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For testing data size 30.0\n",
            "SDE training Error 46.066455372801094\n",
            "SDE testing Error 56.04648758428665\n",
            "Performane 51.05647147854387\n",
            "\n",
            "\n",
            "For testing data size 40.0\n",
            "SDE training Error 46.85079184492609\n",
            "SDE testing Error 51.794463592098616\n",
            "Performane 49.32262771851235\n",
            "\n",
            "\n",
            "For testing data size 50.0\n",
            "SDE training Error 47.200031163445026\n",
            "SDE testing Error 50.2644396140177\n",
            "Performane 48.73223538873136\n",
            "\n",
            "\n",
            "For testing data size 60.0\n",
            "SDE training Error 45.55467657816928\n",
            "SDE testing Error 51.838156040021865\n",
            "Performane 48.69641630909557\n",
            "\n",
            "\n",
            "For testing data size 70.0\n",
            "SDE training Error 46.69720294871339\n",
            "SDE testing Error 50.1686143884938\n",
            "Performane 48.432908668603595\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vvc7JeTYL09"
      },
      "source": [
        "Here if we compare the performance of all the 5 experiments under the hypothesis w0 + w1x + w2x^2. We can observe that the 3th experiment i.e., training : test = 50:50 has the highest value of performance and the 5th experiment i.e., training: test = 30:70 has the lowest value of performance. So, in our case we have seen that the dataset with more test data than training data gives the best performance our of all the others cases since the lower the value of performance the bettter. Also the performance shown by experiment 1-3 are almost identical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJJFv5WtZ-mL"
      },
      "source": [
        "### 9. Consider a dataset (of your choice) which has two input features and 1000 data points. Consider K=200. Train Multiple linear regression model (Mini-batch Gradient descent-with the size of mii-batch as 200 ) with a hypothesis (of your choice). Compute the perfor\u0002mance measure of your mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTfRqjX8bgx-",
        "outputId": "d4b5cc5e-21e1-4d94-8eec-5e7eee2d0764"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Shush25/myDatasets/main/Toyota.csv\",index_col=0,na_values=['??','???','????'])\n",
        "df['Doors'] = df['Doors'].replace('three',3)\n",
        "df['Doors'] = df['Doors'].replace('four',4)\n",
        "df['Doors'] = df['Doors'].replace('five',5)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1436 entries, 0 to 1435\n",
            "Data columns (total 10 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Price      1436 non-null   int64  \n",
            " 1   Age        1336 non-null   float64\n",
            " 2   KM         1421 non-null   float64\n",
            " 3   FuelType   1336 non-null   object \n",
            " 4   HP         1430 non-null   float64\n",
            " 5   MetColor   1286 non-null   float64\n",
            " 6   Automatic  1436 non-null   int64  \n",
            " 7   CC         1436 non-null   int64  \n",
            " 8   Doors      1436 non-null   object \n",
            " 9   Weight     1436 non-null   int64  \n",
            "dtypes: float64(4), int64(4), object(2)\n",
            "memory usage: 123.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL5JAJTGy-C0"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "mean_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "mode_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "df['Age'] = mean_imputer.fit_transform(df['Age'].values.reshape(-1,1))[:,0]\n",
        "df['KM'] = mean_imputer.fit_transform(df['KM'].values.reshape(-1,1))[:,0]\n",
        "mode_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
        "df['FuelType'] = mode_imputer.fit_transform(df['FuelType'].values.reshape(-1,1))[:,0]\n",
        "df['MetColor'] = mode_imputer.fit_transform(df['MetColor'].values.reshape(-1,1))[:,0]\n",
        "df['Doors'] = df['Doors'].astype(int)\n",
        "df.HP = df['HP'].astype('float32')\n",
        "df['HP'] = mean_imputer.fit_transform(df['HP'].values.reshape(-1,1))[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "uSyDjPDdzHw_",
        "outputId": "e35831a1-d501-4ec9-d113-883bfd708b36"
      },
      "source": [
        "# Droping column FuelType since It is non-numerical.\n",
        "df.drop('FuelType', inplace = True, axis = 1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>Age</th>\n",
              "      <th>KM</th>\n",
              "      <th>HP</th>\n",
              "      <th>MetColor</th>\n",
              "      <th>Automatic</th>\n",
              "      <th>CC</th>\n",
              "      <th>Doors</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13500</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>46986.000000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13750</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>72937.000000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13950</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>41711.000000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14950</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>48000.000000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13750</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>38500.000000</td>\n",
              "      <td>90.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2000</td>\n",
              "      <td>3</td>\n",
              "      <td>1170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1431</th>\n",
              "      <td>7500</td>\n",
              "      <td>55.672156</td>\n",
              "      <td>20544.000000</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>1025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1432</th>\n",
              "      <td>10845</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>68647.239972</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>1015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1433</th>\n",
              "      <td>8500</td>\n",
              "      <td>55.672156</td>\n",
              "      <td>17016.000000</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>1015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1434</th>\n",
              "      <td>7250</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>68647.239972</td>\n",
              "      <td>86.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1300</td>\n",
              "      <td>3</td>\n",
              "      <td>1015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>6950</td>\n",
              "      <td>76.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>110.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1600</td>\n",
              "      <td>5</td>\n",
              "      <td>1114</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1436 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Price        Age            KM     HP  ...  Automatic    CC  Doors  Weight\n",
              "0     13500  23.000000  46986.000000   90.0  ...          0  2000      3    1165\n",
              "1     13750  23.000000  72937.000000   90.0  ...          0  2000      3    1165\n",
              "2     13950  24.000000  41711.000000   90.0  ...          0  2000      3    1165\n",
              "3     14950  26.000000  48000.000000   90.0  ...          0  2000      3    1165\n",
              "4     13750  30.000000  38500.000000   90.0  ...          0  2000      3    1170\n",
              "...     ...        ...           ...    ...  ...        ...   ...    ...     ...\n",
              "1431   7500  55.672156  20544.000000   86.0  ...          0  1300      3    1025\n",
              "1432  10845  72.000000  68647.239972   86.0  ...          0  1300      3    1015\n",
              "1433   8500  55.672156  17016.000000   86.0  ...          0  1300      3    1015\n",
              "1434   7250  70.000000  68647.239972   86.0  ...          0  1300      3    1015\n",
              "1435   6950  76.000000      1.000000  110.0  ...          0  1600      5    1114\n",
              "\n",
              "[1436 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "qlQxEDJ3zPoq",
        "outputId": "be399c3c-d90e-47b2-e889-a726f746214b"
      },
      "source": [
        "df = df[:1000]\n",
        "df.drop(['Age','HP','MetColor', 'Automatic','CC','Doors'], axis=1, inplace = True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price</th>\n",
              "      <th>KM</th>\n",
              "      <th>Weight</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13500</td>\n",
              "      <td>46986.0</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13750</td>\n",
              "      <td>72937.0</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13950</td>\n",
              "      <td>41711.0</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14950</td>\n",
              "      <td>48000.0</td>\n",
              "      <td>1165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13750</td>\n",
              "      <td>38500.0</td>\n",
              "      <td>1170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>9950</td>\n",
              "      <td>42750.0</td>\n",
              "      <td>1050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>9950</td>\n",
              "      <td>42102.0</td>\n",
              "      <td>1075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>9950</td>\n",
              "      <td>41586.0</td>\n",
              "      <td>1114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>9900</td>\n",
              "      <td>41200.0</td>\n",
              "      <td>1070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>10950</td>\n",
              "      <td>40214.0</td>\n",
              "      <td>1025</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Price       KM  Weight\n",
              "0    13500  46986.0    1165\n",
              "1    13750  72937.0    1165\n",
              "2    13950  41711.0    1165\n",
              "3    14950  48000.0    1165\n",
              "4    13750  38500.0    1170\n",
              "..     ...      ...     ...\n",
              "995   9950  42750.0    1050\n",
              "996   9950  42102.0    1075\n",
              "997   9950  41586.0    1114\n",
              "998   9900  41200.0    1070\n",
              "999  10950  40214.0    1025\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyip7qSwKRDU"
      },
      "source": [
        "class mini_batch_regressor:\n",
        "\n",
        "  def __init__(self,X):    \n",
        "    self.W = np.random.randn(X.shape[1],1)    \n",
        "    \n",
        "\n",
        "  def fit(self,X, y, learning_rate=0.1, numEpochs=2000, batchsize=200):    \n",
        "    num_of_samples = len(X_test_b)\n",
        "    \n",
        "    for epoch in range(numEpochs):\n",
        "      xbShuffled, yShuffled = shuffle(X, y)\n",
        "      for i in range(0,num_of_samples,batchsize):        \n",
        "        X = xbShuffled[i:i+batchsize]\n",
        "        y = yShuffled[i:i+batchsize]\n",
        "        if len(X)<batchsize:\n",
        "          break        \n",
        "        delta = 1/batchsize*X.T.dot(X.dot(self.W)-y.reshape(-1,1))                        \n",
        "              \n",
        "        self.W = self.W - learning_rate * delta    \n",
        "      learning_rate = learning_rate/1.02  \n",
        "    return self.W\n",
        "    \n",
        "  def predict(self,X,W):\n",
        "    return X.dot(W)\n",
        "\n",
        "  def measure(self,y_predict,y_actual):\n",
        "    return np.sqrt(mean_squared_error(y_predict, y_actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hlxgs4Y0G8l",
        "outputId": "354f9174-f54f-416a-82f1-743b803a06bb"
      },
      "source": [
        "Ones = np.ones(1000)\n",
        "df.insert(0,'Bias',Ones)\n",
        "D = df \n",
        "Arr = np.asarray(df[['Bias','KM','Weight']])\n",
        "size = 0.25\n",
        "X_traind, X_testd, y_traind, y_testd = train_test_split(Arr ,D['Price'], test_size=size, random_state=4)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "X_train = scaler.fit_transform(X_traind)\n",
        "X_test = scaler.transform(X_testd)\n",
        "\n",
        "X_train_b = np.asarray(X_train)\n",
        "Y_train = np.asarray(y_traind)\n",
        "X_test_b = np.asarray(X_test)\n",
        "mgd = mini_batch_regressor(X_train_b)\n",
        "\n",
        "w = mgd.fit(X_train_b,Y_train)\n",
        "predicted_train =mgd.predict(X_train_b,w)\n",
        "rmse_train = mgd.measure(predicted_train,Y_train)\n",
        "predicted_test =mgd.predict(X_test_b,w)\n",
        "rmse_test = mgd.measure(predicted_test,y_testd)\n",
        "print('For test data size', size*100)\n",
        "print('SDE train Error', rmse_train)\n",
        "print('SDE test Error', rmse_test)\n",
        "per = (rmse_train+rmse_test)/2\n",
        "print('Performane', per)\n",
        "print('\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For test data size 25.0\n",
            "SDE train Error 12095.920094210265\n",
            "SDE test Error 12319.994973815225\n",
            "Performane 12207.957534012745\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QtRJoTWOSez"
      },
      "source": [
        "### 10. Download a real-time dataset which has a minimum of 500 datapoints and which could train a regression model. With D, Train a multiple linear regression model (Stochastic Gradient Descent) with polynomial of degree 1 (with all the terms), considering all the input features of the dataset . Compute the error due due to the test data set and the error due to training data set ( split the data set into training data : test data in the ratio 75:25) Also, predict the traget output for an unknown input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "-MprfikjOWy7",
        "outputId": "4c5a2508-8dcc-4f00-e837-12c0e2f9f109"
      },
      "source": [
        "D = pd.read_csv(\"https://raw.githubusercontent.com/Shush25/myDatasets/main/USA_Housing.csv\")\n",
        "D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Avg. Area Income</th>\n",
              "      <th>Avg. Area House Age</th>\n",
              "      <th>Avg. Area Number of Rooms</th>\n",
              "      <th>Avg. Area Number of Bedrooms</th>\n",
              "      <th>Area Population</th>\n",
              "      <th>Price</th>\n",
              "      <th>Address</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79545.458574</td>\n",
              "      <td>5.682861</td>\n",
              "      <td>7.009188</td>\n",
              "      <td>4.09</td>\n",
              "      <td>23086.800503</td>\n",
              "      <td>1.059034e+06</td>\n",
              "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>79248.642455</td>\n",
              "      <td>6.002900</td>\n",
              "      <td>6.730821</td>\n",
              "      <td>3.09</td>\n",
              "      <td>40173.072174</td>\n",
              "      <td>1.505891e+06</td>\n",
              "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61287.067179</td>\n",
              "      <td>5.865890</td>\n",
              "      <td>8.512727</td>\n",
              "      <td>5.13</td>\n",
              "      <td>36882.159400</td>\n",
              "      <td>1.058988e+06</td>\n",
              "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63345.240046</td>\n",
              "      <td>7.188236</td>\n",
              "      <td>5.586729</td>\n",
              "      <td>3.26</td>\n",
              "      <td>34310.242831</td>\n",
              "      <td>1.260617e+06</td>\n",
              "      <td>USS Barnett\\nFPO AP 44820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>59982.197226</td>\n",
              "      <td>5.040555</td>\n",
              "      <td>7.839388</td>\n",
              "      <td>4.23</td>\n",
              "      <td>26354.109472</td>\n",
              "      <td>6.309435e+05</td>\n",
              "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4995</th>\n",
              "      <td>60567.944140</td>\n",
              "      <td>7.830362</td>\n",
              "      <td>6.137356</td>\n",
              "      <td>3.46</td>\n",
              "      <td>22837.361035</td>\n",
              "      <td>1.060194e+06</td>\n",
              "      <td>USNS Williams\\nFPO AP 30153-7653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4996</th>\n",
              "      <td>78491.275435</td>\n",
              "      <td>6.999135</td>\n",
              "      <td>6.576763</td>\n",
              "      <td>4.02</td>\n",
              "      <td>25616.115489</td>\n",
              "      <td>1.482618e+06</td>\n",
              "      <td>PSC 9258, Box 8489\\nAPO AA 42991-3352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4997</th>\n",
              "      <td>63390.686886</td>\n",
              "      <td>7.250591</td>\n",
              "      <td>4.805081</td>\n",
              "      <td>2.13</td>\n",
              "      <td>33266.145490</td>\n",
              "      <td>1.030730e+06</td>\n",
              "      <td>4215 Tracy Garden Suite 076\\nJoshualand, VA 01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4998</th>\n",
              "      <td>68001.331235</td>\n",
              "      <td>5.534388</td>\n",
              "      <td>7.130144</td>\n",
              "      <td>5.44</td>\n",
              "      <td>42625.620156</td>\n",
              "      <td>1.198657e+06</td>\n",
              "      <td>USS Wallace\\nFPO AE 73316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>65510.581804</td>\n",
              "      <td>5.992305</td>\n",
              "      <td>6.792336</td>\n",
              "      <td>4.07</td>\n",
              "      <td>46501.283803</td>\n",
              "      <td>1.298950e+06</td>\n",
              "      <td>37778 George Ridges Apt. 509\\nEast Holly, NV 2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Avg. Area Income  ...                                            Address\n",
              "0         79545.458574  ...  208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...\n",
              "1         79248.642455  ...  188 Johnson Views Suite 079\\nLake Kathleen, CA...\n",
              "2         61287.067179  ...  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...\n",
              "3         63345.240046  ...                          USS Barnett\\nFPO AP 44820\n",
              "4         59982.197226  ...                         USNS Raymond\\nFPO AE 09386\n",
              "...                ...  ...                                                ...\n",
              "4995      60567.944140  ...                   USNS Williams\\nFPO AP 30153-7653\n",
              "4996      78491.275435  ...              PSC 9258, Box 8489\\nAPO AA 42991-3352\n",
              "4997      63390.686886  ...  4215 Tracy Garden Suite 076\\nJoshualand, VA 01...\n",
              "4998      68001.331235  ...                          USS Wallace\\nFPO AE 73316\n",
              "4999      65510.581804  ...  37778 George Ridges Apt. 509\\nEast Holly, NV 2...\n",
              "\n",
              "[5000 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTsFbS1pSaL6",
        "outputId": "363a76ce-beb5-487b-ea9f-b9b3f8554b91"
      },
      "source": [
        "D.drop(['Address'], axis =1, inplace = True)\n",
        "D.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Avg. Area Income                0\n",
              "Avg. Area House Age             0\n",
              "Avg. Area Number of Rooms       0\n",
              "Avg. Area Number of Bedrooms    0\n",
              "Area Population                 0\n",
              "Price                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rErn-D3pUGKv"
      },
      "source": [
        "class sgd_regressor:\n",
        "\n",
        "  def __init__(self,X):    \n",
        "    self.W = np.random.randn(X.shape[1],1)    \n",
        "    \n",
        "\n",
        "  def fit(self,X, y, learning_rate=0.1, numEpochs=2000):\n",
        "    num_of_samples = len(X)\n",
        "    xbShuffled, yShuffled = shuffle(X, y)\n",
        "    for epoch in range(numEpochs):\n",
        "      \n",
        "      for i in range(num_of_samples):        \n",
        "        X = xbShuffled[i:i+1]\n",
        "        yi = yShuffled[i:i+1]\n",
        "        \n",
        "        delta = X.T.dot(X.dot(self.W)-yi.reshape(-1,1))\n",
        "                \n",
        "        self.W = self.W - learning_rate * delta\n",
        "      learning_rate = learning_rate/1.02\n",
        "    return self.W\n",
        "    \n",
        "  def predict(self,X,W):\n",
        "    return X.dot(W)\n",
        "\n",
        "  def measure(self,y_predict,y_actual):\n",
        "    return np.sqrt(mean_squared_error(y_predict, y_actual))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16uFZ-nPTa_l",
        "outputId": "d8ca73aa-c0f4-4f40-8d84-74a7b18d9470"
      },
      "source": [
        "X = D.drop(['Price'], axis = 1) # Every column except Price\n",
        "Y = D['Price'] # Only Price Column\n",
        "Ones = np.ones(X.shape[0])\n",
        "X.insert(0,'Bias',Ones)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = .25, random_state= 3)\n",
        "scaler = MinMaxScaler(feature_range=(0,1))\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_train_b = np.asarray(X_train)\n",
        "Y_train = np.asarray(Y_train)\n",
        "X_test_b = np.asarray(X_test)\n",
        "sgd = sgd_regressor(X_train_b)\n",
        "w = sgd.fit(X_train_b,Y_train)\n",
        "print('weights is ',w)\n",
        "predicted_train =sgd.predict(X_train_b,w)\n",
        "rmse_train = sgd.measure(predicted_train,Y_train)\n",
        "predicted_test =sgd.predict(X_test_b,w)\n",
        "rmse_test = sgd.measure(predicted_test,Y_test)\n",
        "print(\"training predicted error: \", rmse_train)\n",
        "print(\"testing predicted error: \", rmse_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weights is  [[1.29292592e+00]\n",
            " [1.02767609e+06]\n",
            " [5.94643827e+05]\n",
            " [2.57770456e+05]\n",
            " [3.15236320e+04]\n",
            " [5.03353178e+05]]\n",
            "training predicted error:  200679.773515383\n",
            "testing predicted error:  202237.55105724244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L15LXEpiVIBG",
        "outputId": "0aadcacd-8711-4a72-b16d-1693c306e63e"
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "r2_score_train = r2_score(predicted_train, Y_train)\n",
        "r2_score_test = r2_score(predicted_test, Y_test)\n",
        "print('r2_ score for training dataset for multi linear reg : ', r2_score_train)\n",
        "print('r2_ score for testing dataset for multi linear reg : ', r2_score_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2_ score for training dataset for multi linear reg :  -0.37780496165338384\n",
            "r2_ score for testing dataset for multi linear reg :  -0.46896101813295976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "JMfifkPtVMHY",
        "outputId": "2fe329b5-7791-4f52-a3f6-fb3e3d1a8606"
      },
      "source": [
        "sgd.predict(pd.DataFrame([[70000, 9, 7, 5, 1200000, 1000000]]),w)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.411963e+11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0\n",
              "0  5.411963e+11"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    }
  ]
}